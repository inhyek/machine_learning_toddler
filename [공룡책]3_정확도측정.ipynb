{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "[공룡책]3.정확도측정.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inhyek/machine_learning_toddler/blob/master/%5B%EA%B3%B5%EB%A3%A1%EC%B1%85%5D3_%EC%A0%95%ED%99%95%EB%8F%84%EC%B8%A1%EC%A0%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfjk-WWN6fY8",
        "colab_type": "text"
      },
      "source": [
        "## 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi_7mvgv8lKu",
        "colab_type": "code",
        "outputId": "206ee41e-8bae-492c-dab2-f73bc07979d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLQB-X-w81fr",
        "colab_type": "code",
        "outputId": "f99b31d2-2b9c-48a1-cc5e-d6acafd918f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "!ls /gdrive/My\\ Drive/Colab\\ Notebooks/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 탈잉\t\t\t\t      dr\n",
            "'블로그&부동산데이터'\t\t      Iris.csv\n",
            " 여름방학_백준_문제풀이\t\t     'Machine Learning with Iris Dataset.ipynb'\n",
            " 여름방학_머신러닝\t\t      pandas_RNN_LSTM\n",
            "'01.연습문제.ipynb의 사본'\t     'RNN, LSTM, Word2Vec 발표자료.ipynb'\n",
            "'1주차(0724).ipynb'\t\t      titanic_train.csv\n",
            "'3.비지도학습과 데이터전처리.ipynb'   Untitled0.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Mz5_clv6fY9",
        "colab_type": "text"
      },
      "source": [
        "이번 장에서는 모델의 성능을 평가하는 방법에 대해서 배웁니다.\n",
        "보통 성능 평가 지표(Evaluation Metric)는 모델이 분류나 회귀냐에 따라 여러 종류로 나뉩니다.\n",
        "\n",
        "우리가 예전에 배웠던 방법은 모델의 예측값과 실제 값이 얼마나 일치하는 지를 확인하는 'Accuracy(정확도)' 라는 방법이었으나,\n",
        "단순히 정확도만 확인하면 안되는 경우들이 있습니다.\n",
        "\n",
        "따라서, 이번 장에서는 \n",
        "- 이러한 문제들이 발생하게 되는 케이스와 함께 \n",
        "- 평가방법들에 대해서 설명하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTTJrSlZ6fY-",
        "colab_type": "text"
      },
      "source": [
        "먼저 분류의 성능 평가 지표부터 살펴보겠습니다.\n",
        "- 정확도(Accuracy)\n",
        "- 오차행렬(Confusion Matrix)\n",
        "- 정밀도(Precision)\n",
        "- 재현률(Recall)\n",
        "- F1 스코어\n",
        "- ROC AUC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6ZAggkd6fY_",
        "colab_type": "text"
      },
      "source": [
        "## 3-1 Accuracy(정확도)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ekbkd5S6fZA",
        "colab_type": "text"
      },
      "source": [
        "정확도는 실제 데이터에서 예측 데이터가 얼마나 같은지를 판단하는 지표입니다.\n",
        "\n",
        "- 정확도 = 예측결과가 동일한 데이터 건수 / 전체 데이터 건수 \n",
        "\n",
        "정확도는 간결하고 직관적으로 모델 예측 성능을 나타내는 지표입니다.\n",
        "하지만 정확도로만 판단을 하면 문제가 생기는 경우가 있습니다.\n",
        "\n",
        "타이타닉 생존자 예측 과제를 가지고 살펴보면,\n",
        "생존자 중 여자의 비율이 많기 때문에\n",
        "별다른 알고리즘 없이 무조건 성별이 여자인 경우를 생존으로, 남자인 경우를 사망으로 예측해도 비슷한 결과가 나올 수 있습니다.\n",
        "\n",
        "다음 코드는 BaseEstimator 클래스를 상속받아 \n",
        "아무런 학습을 하지 않고.\n",
        "성별에 다라 생존자를 예측하는 단순한 Classifier를 생성해서 학습/예측/평가한 결과입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIpna95S6fZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "class MyDummyClassifier(BaseEstimator):\n",
        "    # fit( ) 메소드는 아무것도 학습하지 않음. \n",
        "    def fit(self , X , y=None):\n",
        "            pass\n",
        "    \n",
        "    ##### predict( ) 메소드는 단순히 Sex feature가 1 이면 0 , 그렇지 않으면 1 로 예측함. #####\n",
        "    def predict(self, X):\n",
        "        pred = np.zeros( ( X.shape[0] , 1))\n",
        "        for i in range (X.shape[0]) :\n",
        "            if X['Sex'].iloc[i] == 1:\n",
        "                pred[i] = 0\n",
        "            else :\n",
        "                pred[i] = 1\n",
        "        \n",
        "        return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-06qBYVo6fZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Null 처리 함수\n",
        "def fillna(df):\n",
        "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
        "    df['Cabin'].fillna('N',inplace=True)\n",
        "    df['Embarked'].fillna('N',inplace=True)\n",
        "    df['Fare'].fillna(0,inplace=True)\n",
        "    return df\n",
        "\n",
        "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
        "def drop_features(df):\n",
        "    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
        "    return df\n",
        "\n",
        "# 레이블 인코딩 수행. \n",
        "def format_features(df):\n",
        "    df['Cabin'] = df['Cabin'].str[:1]\n",
        "    features = ['Cabin','Sex','Embarked']\n",
        "    for feature in features:\n",
        "        le = LabelEncoder()\n",
        "        le = le.fit(df[feature])\n",
        "        df[feature] = le.transform(df[feature])\n",
        "    return df\n",
        "\n",
        "# 앞에서 설정한 Data Preprocessing 함수 호출\n",
        "def transform_features(df):\n",
        "    df = fillna(df)\n",
        "    df = drop_features(df)\n",
        "    df = format_features(df)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZxmloja6fZF",
        "colab_type": "code",
        "outputId": "1d30e005-84f9-4032-eb23-5844291a41df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 원본 데이터를 재로딩, 데이터 가공, 학습데이터/테스트 데이터 분할. \n",
        "titanic_df = pd.read_csv('/gdrive/My Drive/Colab Notebooks/titanic_train.csv')\n",
        "y_titanic_df = titanic_df['Survived']\n",
        "X_titanic_df= titanic_df.drop('Survived', axis=1)\n",
        "X_titanic_df = transform_features(X_titanic_df)\n",
        "X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df, \\\n",
        "                                                  test_size=0.2, random_state=0)\n",
        "\n",
        "# 위에서 생성한 Dummy Classifier를 이용하여 학습/예측/평가 수행. \n",
        "myclf = MyDummyClassifier()\n",
        "myclf.fit(X_train ,y_train)\n",
        "\n",
        "mypredictions = myclf.predict(X_test)\n",
        "print('Dummy Classifier의 정확도는: {0:.4f}'.format(accuracy_score(y_test , mypredictions)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dummy Classifier의 정확도는: 0.7877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZnqNWDTBcp3",
        "colab_type": "text"
      },
      "source": [
        "이렇게 단순한 알고리즘으로 예측을 하더라도 데이터의 구성에 따라 정확도는 78.8%가 나올 수 있습니다.\n",
        "(c.f. label의 개수가 불균형한 경우)\n",
        "\n",
        "###  다음으로 MNIST 데이터셋을 가지고 불균형 데이터셋을 만들어 정확도를 확인해 보겠습니다.\n",
        "\n",
        "- MNIST 란? : 0부터 9까지 숫자에 대한 손글씨 이미지 데이터\n",
        "\n",
        "\n",
        "<img src = \"https://corochann.com/wp-content/uploads/2017/02/mnist_plot-800x600.png\">\n",
        "\n",
        "\n",
        "설명 참고 : https://codeonweb.com/entry/12045839-0aa9-4bad-8c7e-336b89401e10\n",
        "\n",
        "\n",
        "\n",
        "#### multi classification ---> binary classification\n",
        "#### label이 7 인것 = True(10%), label이 7이 아닌 것 = False(90%)으로 변환\n",
        "#### 이름은 MyFakeClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhsciV5AErIT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class MyFakeClassifier(BaseEstimator):\n",
        "    def fit(self,X,y):\n",
        "        pass\n",
        "    \n",
        "    # 입력값으로 들어오는 X 데이터 셋의 크기만큼 모두 0값으로 만들어서 반환\n",
        "    def predict(self,X):\n",
        "        return np.zeros( (len(X),1) , dtype=bool)\n",
        "\n",
        "# 사이킷런의 내장 데이터 셋인 load_digits( )를 이용하여 MNIST 데이터 로딩\n",
        "digits = load_digits()\n",
        "\n",
        "# digits번호가 7번이면 True이고 이를 astype(int)로 1로 변환, 7번이 아니면 False이고 0으로 변환. \n",
        "y = (digits.target == 7).astype(int)\n",
        "X_train, X_test, y_train, y_test = train_test_split( digits.data, y, random_state=11)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODb4pF2fFQVc",
        "colab_type": "code",
        "outputId": "bbe9c3e9-8ae5-4f33-c0af-22621382d620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "# 불균형한 레이블 데이터 분포도 확인. \n",
        "print('레이블 테스트 세트 크기 :', y_test.shape)\n",
        "print('테스트 세트 레이블 0 과 1의 분포도')\n",
        "print(pd.Series(y_test).value_counts())\n",
        "\n",
        "# Dummy Classifier로 학습/예측/정확도 평가\n",
        "fakeclf = MyFakeClassifier()\n",
        "fakeclf.fit(X_train , y_train)\n",
        "fakepred = fakeclf.predict(X_test)\n",
        "print('모든 예측을 0으로 하여도 정확도는:{:.3f}'.format(accuracy_score(y_test , fakepred)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "레이블 테스트 세트 크기 : (450,)\n",
            "테스트 세트 레이블 0 과 1의 분포도\n",
            "0    405\n",
            "1     45\n",
            "dtype: int64\n",
            "모든 예측을 0으로 하여도 정확도는:0.900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRtqzjp16fZN",
        "colab_type": "text"
      },
      "source": [
        "## 3-2 오차행렬(Confusion Matrix)\n",
        "\n",
        "True/False, Positive/Negative의 4분면으로 구성되는 행렬입니다.\n",
        "이 방법으로는\n",
        "- 예측 오류가 얼마인지 뿐만 아니라\n",
        "- **어떠한 유형의 예측 오류**가 발생하고 있는지를\n",
        "알 수 있다는 장점이 있습니다.\n",
        "\n",
        "<img src = \"https://2.bp.blogspot.com/-EvSXDotTOwc/XMfeOGZ-CVI/AAAAAAAAEiE/oePFfvhfOQM11dgRn9FkPxlegCXbgOF4QCLcBGAs/s1600/confusionMatrxiUpdated.jpg\">\n",
        "\n",
        "\n",
        "### [직관적인 버전]\n",
        "\n",
        "\n",
        "\n",
        "<img src = \"https://skappal7.files.wordpress.com/2018/08/confusion-matrix.jpg?w=748\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFp_RwjdEPqt",
        "colab_type": "text"
      },
      "source": [
        "사이킷런은 오차행렬을 구하기 위해   confusion_matrix() API를 제공합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWEt6DEc6fZN",
        "colab_type": "code",
        "outputId": "315309cc-2ef5-476a-a279-f90c1172a5fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# 앞절의 예측 결과인 fakepred와 실제 결과인 y_test의 Confusion Matrix출력\n",
        "confusion_matrix(y_test , fakepred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[405,   0],\n",
              "       [ 45,   0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zhfv7q1gICCC",
        "colab_type": "text"
      },
      "source": [
        "#### TP, TN, FP, FN 값은  Classifier 성능의 여러 면보를 판단할 수 있는 기반 정보를 제공합니다. \n",
        "\n",
        "#### 이 값을 조합해서  Classifier의 성능을 측정할 수 있는 주요 지표인 정확도(Accuracy), 정밀도(Precison), 재현율(Recall)값을 알 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKR6lggnJPph",
        "colab_type": "text"
      },
      "source": [
        "앞에서 소개한 정확도를 가지고 이야기 하면, \n",
        "\n",
        "암 검진 예측 모형이나 사기 판별 모형 등 label이 불균형한 데이터셋에서\n",
        "\n",
        "Positive(양성) 보다는  Negative(음성)로 인해 예측 정확도가 높아지는 경향이 발생하게 되는 것입니다.\n",
        "\n",
        "다음으로 불균형한 데이터셋에서 정확도 보다 더 선호되는 평가 지표인 정밀도(Precision)와 재현율(Recall)에 대해서 알아보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1Ezr5S26fZQ",
        "colab_type": "text"
      },
      "source": [
        "## 3-3 정밀도와 재현율(Precision과 Recall)\n",
        "\n",
        "정밀도와 재현율은 Positive 데이터 세트의 예측 성능에 좀 더 초점을 맞춘 평가 지표입니다.\n",
        "\n",
        "구현 공식은 다음과 같습니다.\n",
        "\n",
        "- 재현율(Recall, Sensitivity) : TP / (FN + TP) - 실제로 답이 Positive인 것 중 Positive 로 예측한 비율 \n",
        "\n",
        "- 정밀도(Precision) : TP/ ( FP + TP)  - Positive라고 예측한 것 중 실제로 답이 Positive인 비율 \n",
        "\n",
        "\n",
        "둘 다 TP를 높이는데 초점이 맞춰져 있지만, 재현율은 FN(실제는 양성인데 음성으로 잘못 예측)를 낮추는데, 정밀도는  FP(실제로는 음성인데 양성으로 잘못 예측)를 낮추는데 초점을 맞춥니다. \n",
        "이 같은 특성 때문에 재현율과 정밀도는 서로 보완적인 지표로 분류의 성능을 평가하는데 적용됩니다.\n",
        "가장 좋은 성능 평가는 두 항목에서 모두 높은 수치를 얻는 것입니다.\n",
        "반면, 둘 중 어느 한 평가 지표만 매우 높고 다른 수치는 매우 낮은 결과를 나타내는 경우는 바람직하지 않습니다.\n",
        "\n",
        "\n",
        "또한, 데이터의 특성에 따라서 재현율 또는 정밀도 중 무엇이 보다 중요한지가 달라질 수 있습니다.\n",
        "\n",
        "재현율이 중요 지표인 경우는 실제 Positive 양성 데이터를 Negative로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우입니다.\n",
        "예를들어 암 판단 모델은 재현율이 훨씬 중요한 지표입니다. 왜냐면 실제 Positive인 환자를 Negative로 예측하는 경우 오류의 대가가 생명을 앗아갈 정도로 심각하기 때문입니다.\n",
        "반면에 실제 Negative인 건강한 환자를 암 환자인 Positive로 예측한 경우면 다시 한 번 재검사를 하는 수준의 비용이 소모될 것입니다.\n",
        "\n",
        "반면, 정밀도가 더 중요한 지표인 경우도 있습니다.\n",
        "예를들어 스팸메일 여부를 판단하는 모델의 경우 실제 Positive인 스팸메일을 Negative인 일반 메일로 분류하더라도 사용자가 불편함을 느끼는 정도이지만, 실제 Negative인 일반 메일을 Positive인 스팸메일로 분류할 경우에는 메일을 아예 받지 못하게 돼 업무에 차질이 생깁니다.\n",
        "\n",
        "- 재현율이 상대적으로 더 중요한 경우는 실제 Positive인 데이터 예측을 Negative로 잘못 판단하게 되면 업무에 큰 영향이 발생하는 경우\n",
        "\n",
        "- 정밀도가 상대적으로 더 중요한 경우는 실제 Negative 음성인 데이터 예측을 Positve 양성으로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9y1EjjYl1LJ",
        "colab_type": "text"
      },
      "source": [
        "### [참고할만한 코드] -오차행렬, 정밀도, 재현율로 예측 성능 평가하기\n",
        "\n",
        "\n",
        "다음은 타이타닉 예제에서 오차행렬, 정밀도, 재현율을 모두 구해서 예측성능을 평가한 것입니다.\n",
        "\n",
        "정밀도 계산은 precison_score()를, 재현율 계산을 위해서는 recall_score()를 사용하면 됩니다. \n",
        "\n",
        "여기서는 평가를 간편하게 적용하기 위해 get_clf_eval() 함수를 만들어서 confusion matrix, accuracy, precision, recall을 평가했습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phq_ujp86fZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score , recall_score , confusion_matrix\n",
        "\n",
        "\n",
        "# 예측성능 평가하는 함수\n",
        "def get_clf_eval(y_test , pred):\n",
        "    confusion = confusion_matrix( y_test, pred)\n",
        "    accuracy = accuracy_score(y_test , pred)\n",
        "    precision = precision_score(y_test , pred)\n",
        "    recall = recall_score(y_test , pred)\n",
        "    print('오차 행렬')\n",
        "    print(confusion)\n",
        "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'.format(accuracy , precision ,recall))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RitpAWk16fZT",
        "colab_type": "code",
        "outputId": "73af65f9-61d7-44d2-d3d8-5af469650dc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "#로지스틱 회귀를 기반으로 타이타닉 생존자를 예측한 후, 예측값에 대한 성능을 평가함\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 원본 데이터를 재로딩, 데이터 가공, 학습데이터/테스트 데이터 분할. \n",
        "titanic_df = pd.read_csv('/gdrive/My Drive/Colab Notebooks/titanic_train.csv')\n",
        "y_titanic_df = titanic_df['Survived']\n",
        "X_titanic_df= titanic_df.drop('Survived', axis=1)\n",
        "X_titanic_df = transform_features(X_titanic_df)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, \\\n",
        "                                                    test_size=0.20, random_state=11)\n",
        "\n",
        "lr_clf = LogisticRegression()\n",
        "\n",
        "lr_clf.fit(X_train , y_train)\n",
        "pred = lr_clf.predict(X_test)\n",
        "get_clf_eval(y_test , pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "오차 행렬\n",
            "[[108  10]\n",
            " [ 14  47]]\n",
            "정확도: 0.8659, 정밀도: 0.8246, 재현율: 0.7705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbiIihr7m5Bk",
        "colab_type": "text"
      },
      "source": [
        "정밀도에 비해 재현율이 낮게 나왔습니다.\n",
        "재현율을 강화할 방법은 무엇일까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh2u4yWk6fZV",
        "colab_type": "text"
      },
      "source": [
        "### 정밀도/재현율 트레이드 오프(Precision/Recall Trade-off)\n",
        "\n",
        "분류하려는 업무의 특성상 정밀도 또는 재현율이 특별히 강조돼야 할 경우 분류의 결정 임곗값(Threshold)을 조정해 정밀도 또는 재현율의 수치를 높일 수 있습니다.\n",
        "\n",
        "하지만 이들은 어느 한 쪽을 강제로 높이면 다른 하나의 수치는 떨어지기 쉬운 Trade-off의 관계에 있습니다. \n",
        "\n",
        "이진분류 모델은 보통 확률값을 0 또는 1로 변환합니다. 가령, 어떤 모델에서 특정 데이터가 0이 될 확률이 10%, 1이 될 확률이 90%라면 최종 예측은 더 큰 확률을 가진 1로 예측합니다. 일반적으로 이진 분류에서는 이 임곗값을   0.5, 즉 50%로 정하고 이 기준값보다 확률이 크면 Positive , 작으면 Negative로 결정합니다.\n",
        "\n",
        "사이킷런에는 개별 데이터별로 예측 확률을 반환하는 메서드인 predict_proba()라는 것이 있습니다. \n",
        "- 입력값: X_test\n",
        "- 출력값: 개별 클래스의 예측확률을 array 형태로 반환. 입력 데이터가 100개이고 예측 클래스가 2개라면 100 x 2의 array로 반환.\n",
        " \n",
        "  각 열은 개별 클래스의 예측 확률임. 첫번째 열은 0의 확률, 두번째 열은 1의 확률임."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqQRP66_6fZW",
        "colab_type": "code",
        "outputId": "33787888-f382-4246-8793-a572a05ade98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "## 바로 앞 예제의 타이타닉 생존자 데이터를 학습한 로지스틱 리그레션 객체에서 predict_proba()메서드를 수행한 뒤 반환값을 확인하고, predict() 메서드의 결과와 비교해 보았습니다.\n",
        "\n",
        "pred_proba = lr_clf.predict_proba(X_test)\n",
        "pred  = lr_clf.predict(X_test)\n",
        "print('pred_proba()결과 Shape : {0}'.format(pred_proba.shape))\n",
        "print('pred_proba array에서 앞 3개만 샘플로 추출 \\n:', pred_proba[:3])\n",
        "\n",
        "# 예측 확률 array 와 예측 결과값 array 를 concatenate 하여 예측 확률과 결과값을 한눈에 확인\n",
        "pred_proba_result = np.concatenate([pred_proba , pred.reshape(-1,1)],axis=1)\n",
        "print('두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \\n',pred_proba_result[:3])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pred_proba()결과 Shape : (179, 2)\n",
            "pred_proba array에서 앞 3개만 샘플로 추출 \n",
            ": [[0.44935227 0.55064773]\n",
            " [0.86335512 0.13664488]\n",
            " [0.86429645 0.13570355]]\n",
            "두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \n",
            " [[0.44935227 0.55064773 1.        ]\n",
            " [0.86335512 0.13664488 0.        ]\n",
            " [0.86429645 0.13570355 0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhxCLpr1rlVl",
        "colab_type": "text"
      },
      "source": [
        "여기서 분류 임계값을 조절해 정밀도와 재현율 수치를 조정할 수 있습니다. \n",
        "\n",
        "\n",
        "Binarizer  클래스를 사용하겠습니다.\n",
        "예제에는 행렬에 있는 숫자들이 1.1이라는 임계치보다 크면 1을, 작으면 0을 반환하는 코드가 구현되어 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKQCqfXt6fZY",
        "colab_type": "code",
        "outputId": "4d2fc01d-d06e-43a8-835a-a1c4a3a9e61f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "## Binarizer를 불러옵니다. \n",
        "from sklearn.preprocessing import Binarizer \n",
        "\n",
        "## X 데이터를 만들었습니다. 3 x3 사이즈 입니다. \n",
        "\n",
        "X = [[ 1, -1,  2],\n",
        "     [ 2,  0,  0],\n",
        "     [ 0,  1.1, 1.2]]\n",
        "\n",
        "# threshold 기준값보다 같거나 작으면 0을, 크면 1을 반환하는 것으로 설정했습니다.\n",
        "binarizer = Binarizer(threshold=1.1)        \n",
        "\n",
        "# fit_transform을 이용하여 X값을 변환합니다.\n",
        "print(binarizer.fit_transform(X))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh_xPKTSslpV",
        "colab_type": "text"
      },
      "source": [
        "바로 앞 예제를 가지고 임계값을 0.5로 설정한 결과를 출력하면, 앞 예제와 동일한 결과가 나옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg44lL8P6fZa",
        "colab_type": "code",
        "outputId": "c22ee94b-fa45-430f-9554-63b12930c649",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "from sklearn.preprocessing import Binarizer\n",
        "\n",
        "#Binarizer의 threshold 설정값. 분류 결정 임곗값임.  \n",
        "custom_threshold = 0.5\n",
        "\n",
        "# predict_proba( ) 반환값의 두번째 컬럼 , 즉 Positive 클래스 컬럼 하나만 추출하여 Binarizer를 적용\n",
        "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
        "\n",
        "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1) \n",
        "custom_predict = binarizer.transform(pred_proba_1)\n",
        "\n",
        "get_clf_eval(y_test, custom_predict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "오차 행렬\n",
            "[[108  10]\n",
            " [ 14  47]]\n",
            "정확도: 0.8659, 정밀도: 0.8246, 재현율: 0.7705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q9mAOhys_B6",
        "colab_type": "text"
      },
      "source": [
        "임계값을 0.4로 낮추고 결과를 출력하면, 정밀도가 낮아지고 재현율이 올라갑니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfdtjNS-6fZc",
        "colab_type": "code",
        "outputId": "c6094060-ec0a-4699-de3c-26d9cd341ef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# Binarizer의 threshold 설정값을 0.4로 설정. 즉 분류 결정 임곗값을 0.5에서 0.4로 낮춤  \n",
        "custom_threshold = 0.4\n",
        "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
        "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1) \n",
        "custom_predict = binarizer.transform(pred_proba_1)\n",
        "\n",
        "get_clf_eval(y_test , custom_predict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "오차 행렬\n",
            "[[97 21]\n",
            " [11 50]]\n",
            "정확도: 0.8212, 정밀도: 0.7042, 재현율: 0.8197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJtNAgNdtO7E",
        "colab_type": "text"
      },
      "source": [
        "이유가 뭘까요? 분류 결정 임곗값은 Positive 예측값을 결정하는 확률의 기준이 됩니다.\n",
        "확률이 0.5가 아닌 0.4부터 Positive로 예측을 더 너그럽게 하기 때문에 임곗값을 낮출수록 True 값이 많아지게 됩니다. \n",
        "\n",
        "이번에는 임곗값을 0.4에서부터 0.6까지 0.05씩 증가시키며 평가지표를 조사하겠습니다. \n",
        "이를 위해 get_eval_by_threshold()함수를 만들겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e4x1pEa6fZe",
        "colab_type": "code",
        "outputId": "7fd029f9-a73d-4651-bbbb-872472e37799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "# 테스트를 수행할 모든 임곗값을 리스트 객체로 저장. \n",
        "thresholds = [0.4, 0.45, 0.50, 0.55, 0.60]\n",
        "\n",
        "def get_eval_by_threshold(y_test , pred_proba_c1, thresholds):\n",
        "    # thresholds list객체내의 값을 차례로 iteration하면서 Evaluation 수행.\n",
        "    for custom_threshold in thresholds:\n",
        "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1) \n",
        "        custom_predict = binarizer.transform(pred_proba_c1)\n",
        "        print('임곗값:',custom_threshold)\n",
        "        get_clf_eval(y_test , custom_predict)\n",
        "\n",
        "get_eval_by_threshold(y_test ,pred_proba[:,1].reshape(-1,1), thresholds )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "임곗값: 0.4\n",
            "오차 행렬\n",
            "[[97 21]\n",
            " [11 50]]\n",
            "정확도: 0.8212, 정밀도: 0.7042, 재현율: 0.8197\n",
            "임곗값: 0.45\n",
            "오차 행렬\n",
            "[[105  13]\n",
            " [ 13  48]]\n",
            "정확도: 0.8547, 정밀도: 0.7869, 재현율: 0.7869\n",
            "임곗값: 0.5\n",
            "오차 행렬\n",
            "[[108  10]\n",
            " [ 14  47]]\n",
            "정확도: 0.8659, 정밀도: 0.8246, 재현율: 0.7705\n",
            "임곗값: 0.55\n",
            "오차 행렬\n",
            "[[111   7]\n",
            " [ 16  45]]\n",
            "정확도: 0.8715, 정밀도: 0.8654, 재현율: 0.7377\n",
            "임곗값: 0.6\n",
            "오차 행렬\n",
            "[[113   5]\n",
            " [ 17  44]]\n",
            "정확도: 0.8771, 정밀도: 0.8980, 재현율: 0.7213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqqqbkKYtv_6",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "임곗값이 0.45일때 디폴트 0.5인 경우와 비교해서 정확도는 동일하고 정밀도는 약간 떨어졌으나 재현율이 올랐습니다.\n",
        "\n",
        "재현율을 향상 시키면서 다른 수치를 어느정도 감소하는 희생을 해야한다면 0.45가 가장 적당해 보입니다.\n",
        "\n",
        "### [참고할만한 코드] - threshold 값 바꿔서 정밀도와 재현율 수치 조정하는 방법\n",
        "\n",
        "\n",
        "지금까지 임곗값 변화에 다른 평가 지표 값을 알아보는 코드를 작성했습니다.\n",
        "\n",
        "**사이킷런은 이와 유사한 precision_recall_cruve() API를 제공합니다.** precision_recall_curve() API의 입력 파라미터와 반환값은 다음과 같습니다.\n",
        "\n",
        "- 입력 파라미터 : y_true(실제 클래스 값), probas_pred(Positive 칼럼의 예측 확률)\n",
        "- 반환 값 : 정밀도(임곗값별 정밀도 값), 재현율(임곗값별 재현율 값)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0Zmo3GF6fZg",
        "colab_type": "code",
        "outputId": "a98f4683-4a5e-48fd-a135-04e2459f2d9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "# 레이블 값이 1일때의 예측 확률을 추출 \n",
        "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1] \n",
        "\n",
        "# 실제값 데이터 셋과 레이블 값이 1일 때의 예측 확률을 precision_recall_curve 인자로 입력 \n",
        "precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_class1 )\n",
        "print('반환된 분류 결정 임곗값 배열의 Shape:', thresholds.shape)\n",
        "\n",
        "#반환된 임계값 배열 로우가 147건이므로 샘플로 10건만 추출하되, 임곗값을 15 Step으로 추출. \n",
        "thr_index = np.arange(0, thresholds.shape[0], 15)\n",
        "print('샘플 추출을 위한 임계값 배열의 index 10개:', thr_index)\n",
        "print('샘플용 10개의 임곗값: ', np.round(thresholds[thr_index], 2))\n",
        "\n",
        "# 15 step 단위로 추출된 임계값에 따른 정밀도와 재현율 값 \n",
        "print('샘플 임계값별 정밀도: ', np.round(precisions[thr_index], 3))\n",
        "print('샘플 임계값별 재현율: ', np.round(recalls[thr_index], 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "반환된 분류 결정 임곗값 배열의 Shape: (147,)\n",
            "샘플 추출을 위한 임계값 배열의 index 10개: [  0  15  30  45  60  75  90 105 120 135]\n",
            "샘플용 10개의 임곗값:  [0.12 0.13 0.15 0.17 0.26 0.38 0.49 0.63 0.76 0.9 ]\n",
            "샘플 임계값별 정밀도:  [0.379 0.424 0.455 0.519 0.618 0.676 0.797 0.93  0.964 1.   ]\n",
            "샘플 임계값별 재현율:  [1.    0.967 0.902 0.902 0.902 0.82  0.77  0.656 0.443 0.213]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGS0BGLavAWC",
        "colab_type": "text"
      },
      "source": [
        "추출된 임곗값 샘플 10개에 해당하는 정밀도 값과 재현율 값을 살펴보면 임곗값이 증가할수록 정밀도 값은 동시에 높아지나 재현율 값은 낮아짐을 알 수 있습니다. precisioin_recall_curve()는 정밀도와 재현율의 임곗값에 따른 값 변화를 곡선 그래프로 시각화 하는데도 이용할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kHp_bvq6fZi",
        "colab_type": "code",
        "outputId": "a855e843-e08b-40d8-ac81-c939662387d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "%matplotlib inline\n",
        "\n",
        "def precision_recall_curve_plot(y_test , pred_proba_c1):\n",
        "    # threshold ndarray와 이 threshold에 따른 정밀도, 재현율 ndarray 추출. \n",
        "    precisions, recalls, thresholds = precision_recall_curve( y_test, pred_proba_c1)\n",
        "    \n",
        "    # X축을 threshold값으로, Y축은 정밀도, 재현율 값으로 각각 Plot 수행. 정밀도는 점선으로 표시\n",
        "    plt.figure(figsize=(8,6))\n",
        "    threshold_boundary = thresholds.shape[0]\n",
        "    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')\n",
        "    plt.plot(thresholds, recalls[0:threshold_boundary],label='recall')\n",
        "    \n",
        "    # threshold 값 X 축의 Scale을 0.1 단위로 변경\n",
        "    start, end = plt.xlim()\n",
        "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
        "    \n",
        "    # x축, y축 label과 legend, 그리고 grid 설정\n",
        "    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n",
        "    plt.legend(); plt.grid()\n",
        "    plt.show()\n",
        "    \n",
        "precision_recall_curve_plot( y_test, lr_clf.predict_proba(X_test)[:, 1] )\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAF3CAYAAAC8MNLCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wiyvjNvva16",
        "colab_type": "text"
      },
      "source": [
        "앞 예제의 로지스틱 회귀 기반의 타이타닉 생존자 예측 모델의 경우 임곗값이 약 0.45인 지점에서 재현율과 정밀도가 비슷해지는 모습을 보였습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irztfV1T6fZk",
        "colab_type": "text"
      },
      "source": [
        "### 3.4 F1 스코어(F1 Score)\n",
        "\n",
        "F1  스코어는 정밀도와 재현율을 결합한 지표입니다.\n",
        "\n",
        "정밀도와 재현율이 어느 한쪽으로 치우치지 않는 수치를 나타낼 때 상대적으로 높은 값을 가집니다.\n",
        "\n",
        "F1 스코어의 공식은 다음과 같습니다.\n",
        "\n",
        "<img src = \"https://chrisalbon.com/images/machine_learning_flashcards/F1_Score_print.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjE1ZFwUzGaA",
        "colab_type": "text"
      },
      "source": [
        "사이킷런은 F1 스코어를 구하기 위해 f1_score()라는 API를 제공합니다.\n",
        "\n",
        "이를 이용해 로지스틱 회귀 기반 타이타닉 생존다 모델의 F1 스코어를 구해보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhnTRsbZ6fZl",
        "colab_type": "code",
        "outputId": "4e949597-a1ad-4153-e4a1-50a45a55412a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# f1_score를 불러옵니다.\n",
        "from sklearn.metrics import f1_score \n",
        "\n",
        "# y_test 값과, 예측값을 넣습니다.\n",
        "f1 = f1_score(y_test , pred)\n",
        "\n",
        "# F1스코어를 출력합니다.\n",
        "print('F1 스코어: {0:.4f}'.format(f1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 스코어: 0.7966\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zukSiDJOzrS9",
        "colab_type": "text"
      },
      "source": [
        "## [참고할만한 코드] 지금까지 배운 평가 지표 + F1스코어 구하기\n",
        "\n",
        "이번에는 타이타닉 생존자 예측에서 임곗값을 변화시키면서  F1 스코어를 포함한 평가 지표를 구해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMqdK03q6fZn",
        "colab_type": "code",
        "outputId": "1a41018f-8da7-4e97-f67c-a712a5f61a7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "def get_clf_eval(y_test , pred):\n",
        "    confusion = confusion_matrix( y_test, pred)\n",
        "    accuracy = accuracy_score(y_test , pred)\n",
        "    precision = precision_score(y_test , pred)\n",
        "    recall = recall_score(y_test , pred)\n",
        "    # F1 스코어 추가\n",
        "    f1 = f1_score(y_test,pred)\n",
        "    print('오차 행렬')\n",
        "    print(confusion)\n",
        "    # f1 score print 추가\n",
        "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1:{3:.4f}'.format(accuracy, precision, recall, f1))\n",
        "\n",
        "thresholds = [0.4 , 0.45 , 0.50 , 0.55 , 0.60]\n",
        "pred_proba = lr_clf.predict_proba(X_test)\n",
        "get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "임곗값: 0.4\n",
            "오차 행렬\n",
            "[[97 21]\n",
            " [11 50]]\n",
            "정확도: 0.8212, 정밀도: 0.7042, 재현율: 0.8197, F1:0.7576\n",
            "임곗값: 0.45\n",
            "오차 행렬\n",
            "[[105  13]\n",
            " [ 13  48]]\n",
            "정확도: 0.8547, 정밀도: 0.7869, 재현율: 0.7869, F1:0.7869\n",
            "임곗값: 0.5\n",
            "오차 행렬\n",
            "[[108  10]\n",
            " [ 14  47]]\n",
            "정확도: 0.8659, 정밀도: 0.8246, 재현율: 0.7705, F1:0.7966\n",
            "임곗값: 0.55\n",
            "오차 행렬\n",
            "[[111   7]\n",
            " [ 16  45]]\n",
            "정확도: 0.8715, 정밀도: 0.8654, 재현율: 0.7377, F1:0.7965\n",
            "임곗값: 0.6\n",
            "오차 행렬\n",
            "[[113   5]\n",
            " [ 17  44]]\n",
            "정확도: 0.8771, 정밀도: 0.8980, 재현율: 0.7213, F1:0.8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnsmKWln0D4G",
        "colab_type": "text"
      },
      "source": [
        "F1 스코어는 임곗값이 0.6일 때 가장 좋은 값을 보여줍니다.\n",
        "하지만 임곗값이 0.6인 경우에는 재현율이 크게 감소하고 있으니 주지해야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKU68c2N6fZq",
        "colab_type": "text"
      },
      "source": [
        "## 3-5 ROC Curve와 AUC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hx1JN7NG0Zu4",
        "colab_type": "text"
      },
      "source": [
        "ROC곡선과 이에 기반한 AUC 스코어는 이진 분류의 예측 성능 측정에서 중요하게 사용되는 지표입니다.\n",
        "\n",
        "Reciever Operation Characteristic Curve. 우리말로 수신자 판단 곡선.\n",
        "\n",
        "이름이 약간 이상한 것은 원래 2차대전 때 통신 장비 성능 평가를 위해 고안된 수치이기 때문입니다.\n",
        "\n",
        "일반적으로 의학 분야에서 많이 사용되지만, \n",
        "\n",
        "머신러닝의 이진 분류 모델의 예측 성능을 판단하는 중요한 평가 지표이기도 합니다.\n",
        "\n",
        "ROC곡선은 FPR(False Positive Rate)이 변할 때 TPR(True Positive Rate - 재현율)이 어떻게 변하는지를 나타내는 곡선입니다.\n",
        "\n",
        "FPR을 X축으로, TRP을 Y축으로 잡으면 FPR의 변화에 따른 TPR의 변화가 곡선 형태로 나타납니다.\n",
        "\n",
        "TRP은  True Positive Rate 으로 재현율을 나타냅니다. 따라서 TP/(FN+TP) 입니다. \n",
        "\n",
        "그리고 재현도에 대응하는 지표로 TNR(True Negative Rate)이라고 불리는 특이성(Specificity)이 있습니다.\n",
        "\n",
        "- TPR은 실제값 Poisitve 가 정확히 예측되어야 하는 수준을 나타냅니다. (질병이 있는 사람은 양성판정)\n",
        "- TNR은 실제값 Negative가 정확히 예측되어야 하는 수준을 나타냅니다. (질병이 없는 사람은 음성판정)\n",
        "- 그리고 ROC 곡선의 X축 기준인 FPR(False Positive Rate)은 1- TNR 또는 1-  특이성으로 표현합니다.\n",
        "\n",
        "\n",
        "\n",
        "- TPR  = TP /(FN+TP)\n",
        "- TNR = TN /(FP+TN)\n",
        "- FPR = FP /(FP+TN) = 1 - TNR = 1 - 특이성 \n",
        "\n",
        "\n",
        "다음은 ROC 곡선의 예입니다. 가운데 직선은 ROC 곡선의 최저값입니다. \n",
        "ROC 곡선이 가운데 직선에 가까울 수록 성능이 떨어지는 것이며 멀어질 수록 성능이 뛰어난 것입니다. \n",
        "\n",
        "\n",
        "<img src = \"https://i.stack.imgur.com/2hrd4.png\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iDKVwx54rRr",
        "colab_type": "text"
      },
      "source": [
        "ROC 곡선은 FPR을 0부터 1까지 변경하면서 TRP의 변화값을 구합니다. 그럼 어떻게 FPR을 0부터 1까지 변경할 수 있을까요?\n",
        "임곗값을 변경하면 됩니다. \n",
        "\n",
        "반대로 FPR을 어떻게 1로 만들 수 있을까요?\n",
        "TN을 0으로 만들면 됩니다.\n",
        "TN을 0으로 만들려면 임곗값을 0으로 지정하면 됩니다.\n",
        "\n",
        "  \n",
        " \n",
        "이렇게 임곗값을 0부터 1까지 변화시키면서 FPR을 구하고 이 FPR 값의 변화에 따른 TPR 값을 구하는 것이 ROC 곡선입니다.\n",
        "\n",
        "(그래서 임곗값을 1부터 0까지 거꾸로 변화시키면서 구한 재현율 곡선의 형태와 비슷합니다.)\n",
        "\n",
        "\n",
        "사이킷런은 ROC 곡선을 구하기 위해 **roc_curve() API**를 제공합니다.\n",
        "\n",
        "사용법은 precision_recall_curve() API와 유사합니다.\n",
        "\n",
        "단지 반환값이 FPR, TPR, 임곗값으로 구성되어 있을 뿐입니다.\n",
        "\n",
        "\n",
        "- 입력 파라미터: y_true(실제 클래스값), y_score(Positive  칼럼의 예측확률)\n",
        "- 반환 값: fpr, tpr, thresholds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-V7jAhGr6fZr",
        "colab_type": "code",
        "outputId": "54abac4c-1552-4cca-a8f3-e8786e3967a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "## 타이타닉 생존자 예측 모델 roc_curve 결과 (FPR, TPR, 임곗값을 알게 됨)\n",
        "\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# 레이블 값이 1일때의 예측 확률을 추출 \n",
        "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1] \n",
        "\n",
        "fprs , tprs , thresholds = roc_curve(y_test, pred_proba_class1)\n",
        "# 반환된 임곗값 배열 로우가 47건이므로 샘플로 10건만 추출하되, 임곗값을 5 Step으로 추출. \n",
        "thr_index = np.arange(0, thresholds.shape[0], 5)\n",
        "print('샘플 추출을 위한 임곗값 배열의 index 10개:', thr_index)\n",
        "print('샘플용 10개의 임곗값: ', np.round(thresholds[thr_index], 2))\n",
        "\n",
        "# 5 step 단위로 추출된 임계값에 따른 FPR, TPR 값\n",
        "print('샘플 임곗값별 FPR: ', np.round(fprs[thr_index], 3))\n",
        "print('샘플 임곗값별 TPR: ', np.round(tprs[thr_index], 3))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "샘플 추출을 위한 임곗값 배열의 index 10개: [ 0  5 10 15 20 25 30 35 40 45]\n",
            "샘플용 10개의 임곗값:  [1.94 0.87 0.63 0.55 0.44 0.32 0.15 0.14 0.13 0.12]\n",
            "샘플 임곗값별 FPR:  [0.    0.008 0.025 0.059 0.127 0.203 0.559 0.602 0.695 0.847]\n",
            "샘플 임곗값별 TPR:  [0.    0.246 0.672 0.738 0.787 0.885 0.902 0.951 0.967 0.984]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0FETRyx6XjO",
        "colab_type": "text"
      },
      "source": [
        "임곗값이 1에 가까운 값에서 점점 작아지면서 FPR이 점점 커집니다.\n",
        "그리고 FPR이 조금씩 커질 때 TPR은 가파르게 커집니다.\n",
        "FPR의 변화에 따른 TPR의 변화를 ROC 곡선으로 시각화해보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeytLyNr6fZu",
        "colab_type": "code",
        "outputId": "5005e8a9-9dc3-4888-9f79-7b9b782bd387",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "def roc_curve_plot(y_test , pred_proba_c1):\n",
        "    # 임곗값에 따른 FPR, TPR 값을 반환 받음. \n",
        "    fprs , tprs , thresholds = roc_curve(y_test ,pred_proba_c1)\n",
        "\n",
        "    # ROC Curve를 plot 곡선으로 그림. \n",
        "    plt.plot(fprs , tprs, label='ROC')\n",
        "    # 가운데 대각선 직선을 그림. \n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "    \n",
        "    # FPR X 축의 Scale을 0.1 단위로 변경, X,Y 축명 설정등   \n",
        "    start, end = plt.xlim()\n",
        "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
        "    plt.xlim(0,1); plt.ylim(0,1)\n",
        "    plt.xlabel('FPR( 1 - Sensitivity )'); plt.ylabel('TPR( Recall )')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "roc_curve_plot(y_test, lr_clf.predict_proba(X_test)[:, 1] )\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyWJFwRhjTBYrCsYYY7JYUTDGGJPl/wO5drrGiSaRHwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAJELEao6oss",
        "colab_type": "text"
      },
      "source": [
        "일반적으로 ROC 곡선 자체는 FPR과 TPR의 변화 값을 보는 데 이용하며 분류의 성능 지표로 사용되는 것은 ROC 곡선 면적에 기반한 AUC 값으로 결정합니다.\n",
        "\n",
        "AUC(Area Under Curve) 값은 ROC 곡선 밑의 면적을 구한 것으로서 일반적으로 1에 가까울수록 좋은 수치입니다.\n",
        "\n",
        "AUC 수치가 커지려면 FPR이 작은 상태에서 얼마나 큰 TPR을 얻을 수 있느냐가 관건입니다.\n",
        "\n",
        "가운데 직선에서 멀어지고 왼쪽 상단 모서리 쪽으로 가파르게 곡선이 이동할수록 직사각형에 가까운 곡선이 되어 면적이 1에 가까워지는 좋은  ROC AUC 성능 수치를 얻게 됩니다. 가운데 대각선 직선은 랜덤 수준의 이진 분류 AUC값으로 0.5입니다. 따라서 보통 분류는 0.5이상의 AUC값을 가집니다.\n",
        "\n",
        "사이킷런은 ROC AUC를 구하기 위해 roc_auc_score() API를 제공합니다.\n",
        "\n",
        "앞의 로지스틱 회귀 타이타닉 예측 모델의 ROC AUC 를 구해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uefH-F0N6fZy",
        "colab_type": "code",
        "outputId": "8b651d3f-e3c9-43ea-82e5-c8bc48498272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "pred = lr_clf.predict(X_test)\n",
        "roc_score = roc_auc_score(y_test, pred)\n",
        "print('ROC AUC 값: {0:.4f}'.format(roc_score))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC AUC 값: 0.8429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlcpjbPq6fZ0",
        "colab_type": "code",
        "outputId": "9b88cfc3-00f6-429c-c9f7-9f966396a295",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "def get_clf_eval(y_test , pred):\n",
        "    confusion = confusion_matrix( y_test, pred)\n",
        "    accuracy = accuracy_score(y_test , pred)\n",
        "    precision = precision_score(y_test , pred)\n",
        "    recall = recall_score(y_test , pred)\n",
        "    f1 = f1_score(y_test,pred)\n",
        "    # ROC-AUC 추가 \n",
        "    roc_auc = roc_auc_score(y_test, pred)\n",
        "    print('오차 행렬')\n",
        "    print(confusion)\n",
        "    # ROC-AUC print 추가\n",
        "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
        "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))\n",
        "    \n",
        "thresholds = [0.4 , 0.45 , 0.50 , 0.55 , 0.60]\n",
        "pred_proba = lr_clf.predict_proba(X_test)\n",
        "get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "임곗값: 0.4\n",
            "오차 행렬\n",
            "[[97 21]\n",
            " [11 50]]\n",
            "정확도: 0.8212, 정밀도: 0.7042, 재현율: 0.8197,    F1: 0.7576, AUC:0.8209\n",
            "임곗값: 0.45\n",
            "오차 행렬\n",
            "[[105  13]\n",
            " [ 13  48]]\n",
            "정확도: 0.8547, 정밀도: 0.7869, 재현율: 0.7869,    F1: 0.7869, AUC:0.8384\n",
            "임곗값: 0.5\n",
            "오차 행렬\n",
            "[[108  10]\n",
            " [ 14  47]]\n",
            "정확도: 0.8659, 정밀도: 0.8246, 재현율: 0.7705,    F1: 0.7966, AUC:0.8429\n",
            "임곗값: 0.55\n",
            "오차 행렬\n",
            "[[111   7]\n",
            " [ 16  45]]\n",
            "정확도: 0.8715, 정밀도: 0.8654, 재현율: 0.7377,    F1: 0.7965, AUC:0.8392\n",
            "임곗값: 0.6\n",
            "오차 행렬\n",
            "[[113   5]\n",
            " [ 17  44]]\n",
            "정확도: 0.8771, 정밀도: 0.8980, 재현율: 0.7213,    F1: 0.8000, AUC:0.8395\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}